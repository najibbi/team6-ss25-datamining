{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08e4fd73-248f-401d-b6a4-0c37bb52551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14\n",
      "  Using cached scipy-1.13.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn<1.4\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn<1.4) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn<1.4) (3.5.0)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Using cached scipy-1.13.1-cp311-cp311-macosx_10_9_x86_64.whl (39.3 MB)\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: numpy, scipy, scikit-learn\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.2.5\n",
      "\u001b[2K    Uninstalling numpy-2.2.5:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.5━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: scipy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.3━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling scipy-1.15.3:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.3━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: scikit-learn[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.6.1━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.6.1:0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.6.1[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [scikit-learn]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aext-panels 4.1.0 requires anaconda-cloud-auth>=0.7.1, which is not installed.\n",
      "aext-panels-server 4.1.0 requires anaconda-cloud-auth>=0.7.1, which is not installed.\n",
      "pyfume 0.3.4 requires numpy==1.24.4, but you have numpy 1.26.4 which is incompatible.\n",
      "pyfume 0.3.4 requires pandas==1.5.3, but you have pandas 2.2.3 which is incompatible.\n",
      "pyfume 0.3.4 requires scipy==1.10.1, but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 scikit-learn-1.3.2 scipy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter cell, prefix with ! \n",
    "!pip install --upgrade 'numpy<2' 'scipy<1.14' 'scikit-learn<1.4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ffdf27-e285-4d34-9a5d-b9df058eb847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\n",
    "# Load your data (adjust path as needed)\n",
    "data_path = \"/Users/hamidahmad/Desktop/Diabetes.csv\"\n",
    "df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9060fa-cc75-47c2-ae2e-2389465e34c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100000, 9)\n",
      "Dtypes:\n",
      " gender                  object\n",
      "age                    float64\n",
      "hypertension             int64\n",
      "heart_disease            int64\n",
      "smoking_history         object\n",
      "bmi                    float64\n",
      "HbA1c_level            float64\n",
      "blood_glucose_level      int64\n",
      "diabetes                 int64\n",
      "dtype: object\n",
      "Missing values per column:\n",
      " gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n",
      "Diabetes distribution (normalized):\n",
      " diabetes\n",
      "0    0.915\n",
      "1    0.085\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Quick Data Inspection\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Dtypes:\\n\", df.dtypes)\n",
    "print(\"Missing values per column:\\n\", df.isna().sum())\n",
    "print(\"Diabetes distribution (normalized):\\n\", df['diabetes'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c3e6b6-26f5-4424-8f3e-5b939cb67f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Feature Lists & Optional Outlier Check\n",
    "numeric_feats = [\n",
    "    \"age\", \"hypertension\", \"heart_disease\", \"bmi\",\n",
    "    \"HbA1c_level\", \"blood_glucose_level\"\n",
    "]\n",
    "categorical_feats = [\"gender\", \"smoking_history\"]\n",
    "target = \"diabetes\"\n",
    "\n",
    "# Optional: boxplots for numeric features\n",
    "# import matplotlib.pyplot as plt\n",
    "# for col in numeric_feats:\n",
    "#     plt.figure()\n",
    "#     df.boxplot(column=col)\n",
    "#     plt.title(f\"Boxplot of {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456b9e1f-b46b-4b52-9a8d-11c981e38644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Preprocessing Pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_feats),\n",
    "    ('cat', categorical_transformer, categorical_feats),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6a0860-af81-4dfa-b206-7b95f308564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (70000, 8), Val: (15000, 8), Test: (15000, 8)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Stratified Train/Val/Test Split\n",
    "X = df[numeric_feats + categorical_feats]\n",
    "y = df[target]\n",
    "\n",
    "# 70% train, 30% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "# Split temp into 15% val, 15% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f9c567a-2728-4538-87a4-3efcf3e31d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline ROC-AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Baseline Dummy Classifier\n",
    "baseline_pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "baseline_pipe.fit(X_train, y_train)\n",
    "y_base_proba = baseline_pipe.predict_proba(X_test)[:, 1]\n",
    "print(\"Baseline ROC-AUC:\", roc_auc_score(y_test, y_base_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218d5bc0-f1d6-4383-aa0a-9a47daaea54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best RF params: {'clf__max_depth': 10, 'clf__min_samples_leaf': 5, 'clf__n_estimators': 200}\n",
      "Validation ROC-AUC: 0.9751471736235476\n",
      "Test ROC-AUC: 0.9767013393335475\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: RandomForest with Class Weights (GridSearchCV)\n",
    "rf_pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [None, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 5],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gs_rf = GridSearchCV(\n",
    "    rf_pipe, param_grid_rf,\n",
    "    cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1\n",
    ")\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best RF params:\", gs_rf.best_params_)\n",
    "print(\"Validation ROC-AUC:\", gs_rf.best_score_)\n",
    "y_rf_proba = gs_rf.predict_proba(X_test)[:, 1]\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_rf_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fb6c2fd-78c6-4749-91f1-c639e00ed41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After upsampling, counts:\n",
      "diabetes\n",
      "0    64050\n",
      "1    64050\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Manual Upsampling of Minority Class\n",
    "# Combine train data\n",
    "df_train = pd.concat([X_train, y_train.rename(target)], axis=1)\n",
    "# Separate classes\n",
    "df_majority = df_train[df_train[target] == 0]\n",
    "df_minority = df_train[df_train[target] == 1]\n",
    "# Upsample minority\n",
    "df_minority_upsampled = resample(\n",
    "    df_minority, replace=True,\n",
    "    n_samples=len(df_majority), random_state=42\n",
    ")\n",
    "# Recombine\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "X_train_up = df_upsampled[numeric_feats + categorical_feats]\n",
    "y_train_up = df_upsampled[target]\n",
    "\n",
    "print(\"After upsampling, counts:\")\n",
    "print(y_train_up.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64fa2a11-34ff-40d0-9275-5e99b01f951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Upsampled RF params: {'clf__max_depth': None, 'clf__n_estimators': 200}\n",
      "Validation ROC-AUC (upsampled): 0.999670683824905\n",
      "Test ROC-AUC (upsampled): 0.96675629843923\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: RandomForest on Upsampled Data\n",
    "rf_up_pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_up = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [None, 5, 10],\n",
    "}\n",
    "\n",
    "gs_up = GridSearchCV(\n",
    "    rf_up_pipe, param_grid_up,\n",
    "    cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1\n",
    ")\n",
    "gs_up.fit(X_train_up, y_train_up)\n",
    "\n",
    "print(\"Best Upsampled RF params:\", gs_up.best_params_)\n",
    "print(\"Validation ROC-AUC (upsampled):\", gs_up.best_score_)\n",
    "y_up_proba = gs_up.predict_proba(X_test)[:, 1]\n",
    "print(\"Test ROC-AUC (upsampled):\", roc_auc_score(y_test, y_up_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5af25884-3d81-49de-97b0-637ac16821af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.085006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.085011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.085068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.085079</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.085170</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14061</th>\n",
       "      <td>0.994586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14062</th>\n",
       "      <td>0.994653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14063</th>\n",
       "      <td>0.995626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14064</th>\n",
       "      <td>0.996309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14065</th>\n",
       "      <td>0.996806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14066 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold  precision    recall\n",
       "0       0.001688   0.085006  1.000000\n",
       "1       0.002901   0.085011  1.000000\n",
       "2       0.003369   0.085068  1.000000\n",
       "3       0.003471   0.085079  1.000000\n",
       "4       0.003531   0.085170  1.000000\n",
       "...          ...        ...       ...\n",
       "14061   0.994586   1.000000  0.003137\n",
       "14062   0.994653   1.000000  0.002353\n",
       "14063   0.995626   1.000000  0.001569\n",
       "14064   0.996309   1.000000  0.000784\n",
       "14065   0.996806   1.000000  0.000000\n",
       "\n",
       "[14066 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 12: Threshold Tuning Table\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get prediction probabilities for the positive class\n",
    "probs = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute precision, recall for many thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "# Align thresholds with the corresponding precision & recall\n",
    "# (precision/recall arrays are one element longer than thresholds)\n",
    "df_thresholds = pd.DataFrame({\n",
    "    'threshold': thresholds,\n",
    "    'precision': precision[1:],   # skip the first element (threshold=-inf)\n",
    "    'recall':    recall[1:]\n",
    "})\n",
    "\n",
    "# Display the full table (or use .head() to show top 10)\n",
    "df_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae361669-ce95-40c9-b264-16faddbcd522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
